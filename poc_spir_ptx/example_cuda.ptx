//
// Generated by LLVM NVPTX Back-End
//

.version 3.2
.target sm_30
.address_size 64

.weak .func _ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb
(
	.param .b64 _ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb_param_0,
	.param .b64 _ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb_param_1,
	.param .b64 _ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb_param_2,
	.param .b32 _ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb_param_3
)
;
.weak .func _ZN18simple_intersector9intersectERK3ray
(
	.param .b64 _ZN18simple_intersector9intersectERK3ray_param_0,
	.param .b64 _ZN18simple_intersector9intersectERK3ray_param_1
)
;
.weak .func _ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj
(
	.param .b64 _ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_0,
	.param .b64 _ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_1,
	.param .b64 _ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_2,
	.param .b64 _ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_3,
	.param .b64 _ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_4
)
;
.weak .func _ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj
(
	.param .b64 _ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_0,
	.param .b64 _ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_1,
	.param .b64 _ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_2,
	.param .b64 _ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_3,
	.param .b64 _ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_4
)
;
.weak .func _ZN18simple_path_tracer16get_local_systemERK7vector3IfE
(
	.param .b64 _ZN18simple_path_tracer16get_local_systemERK7vector3IfE_param_0,
	.param .b64 _ZN18simple_path_tracer16get_local_systemERK7vector3IfE_param_1
)
;
.const .align 4 .b8 _ZL16cornell_vertices[768] = {0, 0, 92, 66, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 174, 95, 66, 0, 0, 92, 66, 0, 0, 0, 0, 20, 174, 95, 66, 51, 51, 9, 66, 51, 51, 91, 66, 154, 153, 181, 65, 51, 51, 9, 66, 51, 51, 91, 66, 205, 204, 4, 66, 102, 102, 170, 65, 51, 51, 91, 66, 205, 204, 4, 66, 102, 102, 170, 65, 51, 51, 91, 66, 154, 153, 181, 65, 0, 0, 92, 66, 31, 133, 91, 66, 0, 0, 0, 0, 0, 0, 92, 66, 31, 133, 91, 66, 20, 174, 95, 66, 0, 0, 0, 0, 31, 133, 91, 66, 20, 174, 95, 66, 0, 0, 0, 0, 31, 133, 91, 66, 0, 0, 0, 0, 0, 0, 92, 66, 0, 0, 0, 0, 20, 174, 95, 66, 0, 0, 0, 0, 0, 0, 0, 0, 20, 174, 95, 66, 0, 0, 0, 0, 31, 133, 91, 66, 20, 174, 95, 66, 0, 0, 92, 66, 31, 133, 91, 66, 20, 174, 95, 66, 0, 0, 0, 0, 0, 0, 0, 0, 20, 174, 95, 66, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 31, 133, 91, 66, 0, 0, 0, 0, 0, 0, 0, 0, 31, 133, 91, 66, 20, 174, 95, 66, 0, 0, 92, 66, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 92, 66, 0, 0, 0, 0, 20, 174, 95, 66, 0, 0, 92, 66, 31, 133, 91, 66, 20, 174, 95, 66, 0, 0, 92, 66, 31, 133, 91, 66, 0, 0, 0, 0, 0, 0, 80, 65, 0, 0, 132, 65, 0, 0, 208, 64, 51, 51, 3, 65, 0, 0, 132, 65, 0, 0, 180, 65, 0, 0, 192, 65, 0, 0, 132, 65, 154, 153, 217, 65, 0, 0, 232, 65, 0, 0, 132, 65, 102, 102, 54, 65, 0, 0, 232, 65, 0, 0, 0, 0, 102, 102, 54, 65, 0, 0, 232, 65, 0, 0, 132, 65, 102, 102, 54, 65, 0, 0, 192, 65, 0, 0, 132, 65, 154, 153, 217, 65, 0, 0, 192, 65, 0, 0, 0, 0, 154, 153, 217, 65, 0, 0, 80, 65, 0, 0, 0, 0, 0, 0, 208, 64, 0, 0, 80, 65, 0, 0, 132, 65, 0, 0, 208, 64, 0, 0, 232, 65, 0, 0, 132, 65, 102, 102, 54, 65, 0, 0, 232, 65, 0, 0, 0, 0, 102, 102, 54, 65, 51, 51, 3, 65, 0, 0, 0, 0, 0, 0, 180, 65, 51, 51, 3, 65, 0, 0, 132, 65, 0, 0, 180, 65, 0, 0, 80, 65, 0, 0, 132, 65, 0, 0, 208, 64, 0, 0, 80, 65, 0, 0, 0, 0, 0, 0, 208, 64, 0, 0, 192, 65, 0, 0, 0, 0, 154, 153, 217, 65, 0, 0, 192, 65, 0, 0, 132, 65, 154, 153, 217, 65, 51, 51, 3, 65, 0, 0, 132, 65, 0, 0, 180, 65, 51, 51, 3, 65, 0, 0, 0, 0, 0, 0, 180, 65, 51, 51, 41, 66, 0, 0, 4, 66, 154, 153, 197, 65, 0, 0, 212, 65, 0, 0, 4, 66, 205, 204, 236, 65, 51, 51, 251, 65, 0, 0, 4, 66, 102, 102, 54, 66, 205, 204, 60, 66, 0, 0, 4, 66, 102, 102, 34, 66, 51, 51, 41, 66, 0, 0, 0, 0, 154, 153, 197, 65, 51, 51, 41, 66, 0, 0, 4, 66, 154, 153, 197, 65, 205, 204, 60, 66, 0, 0, 4, 66, 102, 102, 34, 66, 205, 204, 60, 66, 0, 0, 0, 0, 102, 102, 34, 66, 205, 204, 60, 66, 0, 0, 0, 0, 102, 102, 34, 66, 205, 204, 60, 66, 0, 0, 4, 66, 102, 102, 34, 66, 51, 51, 251, 65, 0, 0, 4, 66, 102, 102, 54, 66, 51, 51, 251, 65, 0, 0, 0, 0, 102, 102, 54, 66, 51, 51, 251, 65, 0, 0, 0, 0, 102, 102, 54, 66, 51, 51, 251, 65, 0, 0, 4, 66, 102, 102, 54, 66, 0, 0, 212, 65, 0, 0, 4, 66, 205, 204, 236, 65, 0, 0, 212, 65, 0, 0, 0, 0, 205, 204, 236, 65, 0, 0, 212, 65, 0, 0, 0, 0, 205, 204, 236, 65, 0, 0, 212, 65, 0, 0, 4, 66, 205, 204, 236, 65, 51, 51, 41, 66, 0, 0, 4, 66, 154, 153, 197, 65, 51, 51, 41, 66, 0, 0, 0, 0, 154, 153, 197, 65};
.const .align 4 .b8 _ZL15cornell_indices[384] = {0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 4, 0, 0, 0, 5, 0, 0, 0, 6, 0, 0, 0, 4, 0, 0, 0, 6, 0, 0, 0, 7, 0, 0, 0, 8, 0, 0, 0, 9, 0, 0, 0, 10, 0, 0, 0, 8, 0, 0, 0, 10, 0, 0, 0, 11, 0, 0, 0, 12, 0, 0, 0, 13, 0, 0, 0, 14, 0, 0, 0, 12, 0, 0, 0, 14, 0, 0, 0, 15, 0, 0, 0, 16, 0, 0, 0, 17, 0, 0, 0, 18, 0, 0, 0, 16, 0, 0, 0, 18, 0, 0, 0, 19, 0, 0, 0, 20, 0, 0, 0, 21, 0, 0, 0, 22, 0, 0, 0, 20, 0, 0, 0, 22, 0, 0, 0, 23, 0, 0, 0, 24, 0, 0, 0, 25, 0, 0, 0, 26, 0, 0, 0, 24, 0, 0, 0, 26, 0, 0, 0, 27, 0, 0, 0, 28, 0, 0, 0, 29, 0, 0, 0, 30, 0, 0, 0, 28, 0, 0, 0, 30, 0, 0, 0, 31, 0, 0, 0, 32, 0, 0, 0, 33, 0, 0, 0, 34, 0, 0, 0, 32, 0, 0, 0, 34, 0, 0, 0, 35, 0, 0, 0, 36, 0, 0, 0, 37, 0, 0, 0, 38, 0, 0, 0, 36, 0, 0, 0, 38, 0, 0, 0, 39, 0, 0, 0, 40, 0, 0, 0, 41, 0, 0, 0, 42, 0, 0, 0, 40, 0, 0, 0, 42, 0, 0, 0, 43, 0, 0, 0, 44, 0, 0, 0, 45, 0, 0, 0, 46, 0, 0, 0, 44, 0, 0, 0, 46, 0, 0, 0, 47, 0, 0, 0, 48, 0, 0, 0, 49, 0, 0, 0, 50, 0, 0, 0, 48, 0, 0, 0, 50, 0, 0, 0, 51, 0, 0, 0, 52, 0, 0, 0, 53, 0, 0, 0, 54, 0, 0, 0, 52, 0, 0, 0, 54, 0, 0, 0, 55, 0, 0, 0, 56, 0, 0, 0, 57, 0, 0, 0, 58, 0, 0, 0, 56, 0, 0, 0, 58, 0, 0, 0, 59, 0, 0, 0, 60, 0, 0, 0, 61, 0, 0, 0, 62, 0, 0, 0, 60, 0, 0, 0, 62, 0, 0, 0, 63, 0, 0, 0};
.const .align 4 .b8 _ZL17cornell_materials[512] = {204, 208, 208, 62, 204, 208, 208, 62, 204, 208, 208, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 167, 239, 4, 62, 167, 239, 4, 62, 167, 239, 4, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 205, 204, 76, 62, 205, 204, 76, 62, 205, 204, 76, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 65, 0, 0, 112, 65, 0, 0, 112, 65, 0, 0, 112, 65, 54, 97, 130, 61, 54, 97, 130, 61, 54, 97, 130, 61, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 204, 208, 208, 62, 204, 208, 208, 62, 204, 208, 208, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 167, 239, 4, 62, 167, 239, 4, 62, 167, 239, 4, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 204, 208, 208, 62, 204, 208, 208, 62, 204, 208, 208, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 167, 239, 4, 62, 167, 239, 4, 62, 167, 239, 4, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 204, 208, 208, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 167, 239, 4, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 204, 208, 208, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 167, 239, 4, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 204, 208, 208, 62, 204, 208, 208, 62, 204, 208, 208, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 167, 239, 4, 62, 167, 239, 4, 62, 167, 239, 4, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 205, 204, 204, 61, 205, 204, 204, 61, 205, 204, 204, 61, 102, 102, 102, 63, 102, 102, 102, 63, 102, 102, 102, 63, 0, 0, 200, 66, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 54, 97, 2, 61, 54, 97, 2, 61, 54, 97, 2, 61, 74, 196, 105, 65, 74, 196, 105, 65, 74, 196, 105, 65};
.const .align 4 .b8 _ZL18cornell_object_map[128] = {0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 6, 0, 0, 0, 6, 0, 0, 0, 6, 0, 0, 0, 6, 0, 0, 0, 6, 0, 0, 0, 6, 0, 0, 0, 6, 0, 0, 0, 6, 0, 0, 0, 6, 0, 0, 0, 6, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0};
                                        // @_Z3powff
.visible .func  (.param .b32 func_retval0) _Z3powff(
	.param .b32 _Z3powff_param_0,
	.param .b32 _Z3powff_param_1
)
{
	.reg .f32 	%f<6>;

// BB#0:
	ld.param.f32 	%f1, [_Z3powff_param_0];
	lg2.approx.ftz.f32 	%f2, %f1;
	ld.param.f32 	%f3, [_Z3powff_param_1];
	mul.f32 	%f4, %f2, %f3;
	ex2.approx.ftz.f32 	%f5, %f4;
	st.param.f32	[func_retval0+0], %f5;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z4sqrtf(
	.param .b32 _Z4sqrtf_param_0
)                                       // @_Z4sqrtf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [_Z4sqrtf_param_0];
	sqrt.rn.ftz.f32 	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z3sinf(
	.param .b32 _Z3sinf_param_0
)                                       // @_Z3sinf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [_Z3sinf_param_0];
	sin.approx.ftz.f32 	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z3cosf(
	.param .b32 _Z3cosf_param_0
)                                       // @_Z3cosf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [_Z3cosf_param_0];
	cos.approx.ftz.f32 	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z3tanf(
	.param .b32 _Z3tanf_param_0
)                                       // @_Z3tanf
{
	.reg .f32 	%f<5>;

// BB#0:
	ld.param.f32 	%f1, [_Z3tanf_param_0];
	cos.approx.ftz.f32 	%f2, %f1;
	sin.approx.ftz.f32 	%f3, %f1;
	div.approx.f32 	%f4, %f3, %f2;
	st.param.f32	[func_retval0+0], %f4;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_fmodf(
	.param .b32 floor__const_math_fmodf_param_0,
	.param .b32 floor__const_math_fmodf_param_1
)                                       // @floor__const_math_fmodf
{
	.reg .f32 	%f<7>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_fmodf_param_1];
	ld.param.f32 	%f2, [floor__const_math_fmodf_param_0];
	div.approx.f32 	%f3, %f2, %f1;
	cvt.rzi.ftz.f32.f32	%f4, %f3;
	neg.f32 	%f5, %f4;
	fma.rn.f32 	%f6, %f5, %f1, %f2;
	st.param.f32	[func_retval0+0], %f6;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_sqrtf(
	.param .b32 floor__const_math_sqrtf_param_0
)                                       // @floor__const_math_sqrtf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_sqrtf_param_0];
	sqrt.rz.ftz.f32 	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_inv_sqrtf(
	.param .b32 floor__const_math_inv_sqrtf_param_0
)                                       // @floor__const_math_inv_sqrtf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_inv_sqrtf_param_0];
	rsqrt.approx.ftz.f32 	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_absf(
	.param .b32 floor__const_math_absf_param_0
)                                       // @floor__const_math_absf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_absf_param_0];
	abs.ftz.f32 	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_floorf(
	.param .b32 floor__const_math_floorf_param_0
)                                       // @floor__const_math_floorf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_floorf_param_0];
	cvt.rmi.ftz.f32.f32	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_ceilf(
	.param .b32 floor__const_math_ceilf_param_0
)                                       // @floor__const_math_ceilf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_ceilf_param_0];
	cvt.rpi.ftz.f32.f32	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_roundf(
	.param .b32 floor__const_math_roundf_param_0
)                                       // @floor__const_math_roundf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_roundf_param_0];
	cvt.rni.ftz.f32.f32	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_truncf(
	.param .b32 floor__const_math_truncf_param_0
)                                       // @floor__const_math_truncf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_truncf_param_0];
	cvt.rzi.ftz.f32.f32	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_rintf(
	.param .b32 floor__const_math_rintf_param_0
)                                       // @floor__const_math_rintf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_rintf_param_0];
	cvt.rzi.ftz.f32.f32	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_sinf(
	.param .b32 floor__const_math_sinf_param_0
)                                       // @floor__const_math_sinf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_sinf_param_0];
	sin.approx.ftz.f32 	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_cosf(
	.param .b32 floor__const_math_cosf_param_0
)                                       // @floor__const_math_cosf
{
	.reg .f32 	%f<3>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_cosf_param_0];
	cos.approx.ftz.f32 	%f2, %f1;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_tanf(
	.param .b32 floor__const_math_tanf_param_0
)                                       // @floor__const_math_tanf
{
	.reg .f32 	%f<5>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_tanf_param_0];
	cos.approx.ftz.f32 	%f2, %f1;
	sin.approx.ftz.f32 	%f3, %f1;
	div.approx.f32 	%f4, %f3, %f2;
	st.param.f32	[func_retval0+0], %f4;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_asinf(
	.param .b32 floor__const_math_asinf_param_0
)                                       // @floor__const_math_asinf
{
	.reg .f32 	%f<2>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_asinf_param_0];
	st.param.f32	[func_retval0+0], %f1;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_acosf(
	.param .b32 floor__const_math_acosf_param_0
)                                       // @floor__const_math_acosf
{
	.reg .f32 	%f<2>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_acosf_param_0];
	st.param.f32	[func_retval0+0], %f1;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_atanf(
	.param .b32 floor__const_math_atanf_param_0
)                                       // @floor__const_math_atanf
{
	.reg .f32 	%f<2>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_atanf_param_0];
	st.param.f32	[func_retval0+0], %f1;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_atan2f(
	.param .b32 floor__const_math_atan2f_param_0,
	.param .b32 floor__const_math_atan2f_param_1
)                                       // @floor__const_math_atan2f
{
	.reg .f32 	%f<4>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_atan2f_param_1];
	ld.param.f32 	%f2, [floor__const_math_atan2f_param_0];
	add.f32 	%f3, %f2, %f1;
	st.param.f32	[func_retval0+0], %f3;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_fmaf(
	.param .b32 floor__const_math_fmaf_param_0,
	.param .b32 floor__const_math_fmaf_param_1,
	.param .b32 floor__const_math_fmaf_param_2
)                                       // @floor__const_math_fmaf
{
	.reg .f32 	%f<5>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_fmaf_param_2];
	ld.param.f32 	%f2, [floor__const_math_fmaf_param_1];
	ld.param.f32 	%f3, [floor__const_math_fmaf_param_0];
	fma.rz.ftz.f32 	%f4, %f3, %f2, %f1;
	st.param.f32	[func_retval0+0], %f4;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_expf(
	.param .b32 floor__const_math_expf_param_0
)                                       // @floor__const_math_expf
{
	.reg .f32 	%f<4>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_expf_param_0];
	mul.f32 	%f2, %f1, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f3, %f2;
	st.param.f32	[func_retval0+0], %f3;
	ret;
}

.visible .func  (.param .b32 func_retval0) floor__const_math_logf(
	.param .b32 floor__const_math_logf_param_0
)                                       // @floor__const_math_logf
{
	.reg .f32 	%f<4>;

// BB#0:
	ld.param.f32 	%f1, [floor__const_math_logf_param_0];
	lg2.approx.ftz.f32 	%f2, %f1;
	mul.f32 	%f3, %f2, 0f3FB8AA3B;
	st.param.f32	[func_retval0+0], %f3;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_fmodd(
	.param .b64 floor__const_math_fmodd_param_0,
	.param .b64 floor__const_math_fmodd_param_1
)                                       // @floor__const_math_fmodd
{
	.reg .f64 	%fd<7>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_fmodd_param_1];
	ld.param.f64 	%fd2, [floor__const_math_fmodd_param_0];
	div.rn.f64 	%fd3, %fd2, %fd1;
	cvt.rzi.f64.f64	%fd4, %fd3;
	neg.f64 	%fd5, %fd4;
	fma.rn.f64 	%fd6, %fd5, %fd1, %fd2;
	st.param.f64	[func_retval0+0], %fd6;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_sqrtd(
	.param .b64 floor__const_math_sqrtd_param_0
)                                       // @floor__const_math_sqrtd
{
	.reg .f64 	%fd<3>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_sqrtd_param_0];
	sqrt.rz.f64 	%fd2, %fd1;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_inv_sqrtd(
	.param .b64 floor__const_math_inv_sqrtd_param_0
)                                       // @floor__const_math_inv_sqrtd
{
	.reg .f64 	%fd<3>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_inv_sqrtd_param_0];
	rsqrt.approx.f64 	%fd2, %fd1;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_absd(
	.param .b64 floor__const_math_absd_param_0
)                                       // @floor__const_math_absd
{
	.reg .f64 	%fd<3>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_absd_param_0];
	abs.f64 	%fd2, %fd1;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_floord(
	.param .b64 floor__const_math_floord_param_0
)                                       // @floor__const_math_floord
{
	.reg .f64 	%fd<3>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_floord_param_0];
	cvt.rmi.f64.f64	%fd2, %fd1;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_ceild(
	.param .b64 floor__const_math_ceild_param_0
)                                       // @floor__const_math_ceild
{
	.reg .f64 	%fd<3>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_ceild_param_0];
	cvt.rpi.f64.f64	%fd2, %fd1;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_roundd(
	.param .b64 floor__const_math_roundd_param_0
)                                       // @floor__const_math_roundd
{
	.reg .f64 	%fd<3>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_roundd_param_0];
	cvt.rni.f64.f64	%fd2, %fd1;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_truncd(
	.param .b64 floor__const_math_truncd_param_0
)                                       // @floor__const_math_truncd
{
	.reg .f64 	%fd<3>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_truncd_param_0];
	cvt.rzi.f64.f64	%fd2, %fd1;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_rintd(
	.param .b64 floor__const_math_rintd_param_0
)                                       // @floor__const_math_rintd
{
	.reg .f64 	%fd<3>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_rintd_param_0];
	cvt.rzi.f64.f64	%fd2, %fd1;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_sind(
	.param .b64 floor__const_math_sind_param_0
)                                       // @floor__const_math_sind
{
	.reg .f32 	%f<3>;
	.reg .f64 	%fd<3>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_sind_param_0];
	cvt.rn.f32.f64	%f1, %fd1;
	sin.approx.ftz.f32 	%f2, %f1;
	cvt.f64.f32	%fd2, %f2;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_cosd(
	.param .b64 floor__const_math_cosd_param_0
)                                       // @floor__const_math_cosd
{
	.reg .f32 	%f<3>;
	.reg .f64 	%fd<3>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_cosd_param_0];
	cvt.rn.f32.f64	%f1, %fd1;
	cos.approx.ftz.f32 	%f2, %f1;
	cvt.f64.f32	%fd2, %f2;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_tand(
	.param .b64 floor__const_math_tand_param_0
)                                       // @floor__const_math_tand
{
	.reg .f32 	%f<5>;
	.reg .f64 	%fd<3>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_tand_param_0];
	cvt.rn.f32.f64	%f1, %fd1;
	cos.approx.ftz.f32 	%f2, %f1;
	sin.approx.ftz.f32 	%f3, %f1;
	div.approx.f32 	%f4, %f3, %f2;
	cvt.f64.f32	%fd2, %f4;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_asind(
	.param .b64 floor__const_math_asind_param_0
)                                       // @floor__const_math_asind
{
	.reg .f64 	%fd<2>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_asind_param_0];
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_acosd(
	.param .b64 floor__const_math_acosd_param_0
)                                       // @floor__const_math_acosd
{
	.reg .f64 	%fd<2>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_acosd_param_0];
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_atand(
	.param .b64 floor__const_math_atand_param_0
)                                       // @floor__const_math_atand
{
	.reg .f64 	%fd<2>;

// BB#0:
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_atan2d(
	.param .b64 floor__const_math_atan2d_param_0,
	.param .b64 floor__const_math_atan2d_param_1
)                                       // @floor__const_math_atan2d
{
	.reg .f64 	%fd<4>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_atan2d_param_1];
	ld.param.f64 	%fd2, [floor__const_math_atan2d_param_0];
	add.f64 	%fd3, %fd2, %fd1;
	st.param.f64	[func_retval0+0], %fd3;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_fmad(
	.param .b64 floor__const_math_fmad_param_0,
	.param .b64 floor__const_math_fmad_param_1,
	.param .b64 floor__const_math_fmad_param_2
)                                       // @floor__const_math_fmad
{
	.reg .f64 	%fd<5>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_fmad_param_2];
	ld.param.f64 	%fd2, [floor__const_math_fmad_param_1];
	ld.param.f64 	%fd3, [floor__const_math_fmad_param_0];
	fma.rz.f64 	%fd4, %fd3, %fd2, %fd1;
	st.param.f64	[func_retval0+0], %fd4;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_expd(
	.param .b64 floor__const_math_expd_param_0
)                                       // @floor__const_math_expd
{
	.reg .f32 	%f<4>;
	.reg .f64 	%fd<3>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_expd_param_0];
	cvt.rn.f32.f64	%f1, %fd1;
	mul.f32 	%f2, %f1, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f3, %f2;
	cvt.f64.f32	%fd2, %f3;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.visible .func  (.param .b64 func_retval0) floor__const_math_logd(
	.param .b64 floor__const_math_logd_param_0
)                                       // @floor__const_math_logd
{
	.reg .f32 	%f<3>;
	.reg .f64 	%fd<4>;

// BB#0:
	ld.param.f64 	%fd1, [floor__const_math_logd_param_0];
	cvt.rn.f32.f64	%f1, %fd1;
	lg2.approx.ftz.f32 	%f2, %f1;
	cvt.f64.f32	%fd2, %f2;
	mul.f64 	%fd3, %fd2, 0d3FF715476533245E;
	st.param.f64	[func_retval0+0], %fd3;
	ret;
}

.visible .entry path_trace(
	.param .u64 path_trace_param_0,
	.param .u32 path_trace_param_1,
	.param .u32 path_trace_param_2,
	.param .align 4 .b8 path_trace_param_3[8]
)                                       // @path_trace
{
	.local .align 8 .b8 	__local_depot43[48];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .s16 	%rs<2>;
	.reg .f32 	%f<50>;
	.reg .s32 	%r<32>;
	.reg .s64 	%rd<15>;

// BB#0:
	mov.u64 	%rd14, __local_depot43;
	cvta.local.u64 	%SP, %rd14;
	mov.u32	%r3, %tid.x;
	mov.u32	%r4, %ctaid.x;
	mov.u32	%r5, %ntid.x;
	mad.lo.s32 	%r1, %r5, %r4, %r3;
	ld.param.u32 	%r2, [path_trace_param_1];
	add.s32 	%r6, %r1, %r2;
	ld.param.u32 	%r7, [path_trace_param_2];
	and.b32  	%r8, %r7, %r6;
	and.b32  	%r9, %r8, 31;
	shl.b32 	%r10, %r1, %r9;
	xor.b32  	%r11, %r10, %r7;
	add.s32 	%r12, %r1, %r7;
	ld.param.u32 	%r13, [path_trace_param_3];
	ld.param.u32 	%r14, [path_trace_param_3+4];
	mul.lo.s32 	%r15, %r14, %r13;
	mad.lo.s32 	%r16, %r15, %r12, %r7;
	add.s32 	%r17, %r16, %r11;
	xor.b32  	%r18, %r17, 1392237036;
	mul.lo.s32 	%r19, %r18, 282475249;
	st.u32 	[%SP+0], %r19;
	mov.u32 	%r20, 1105094246;
	st.u32 	[%SP+8], %r20;
	add.u64 	%rd2, %SP, 8;
	or.b64  	%rd3, %rd2, 4;
	mov.u32 	%r21, 1104832102;
	st.u32 	[%rd3], %r21;
	mov.u32 	%r22, -1029701632;
	st.u32 	[%SP+16], %r22;
	mul.lo.s32 	%r23, %r18, 16807;
	shr.u32 	%r24, %r23, 9;
	or.b32  	%r25, %r24, 1065353216;
	mov.b32 	 %f2, %r25;
	add.f32 	%f3, %f2, 0fBF800000;
	rem.u32 	%r26, %r1, %r13;
	cvt.rn.f32.u32	%f4, %r26;
	add.f32 	%f5, %f4, %f3;
	cvt.rn.f32.u32	%f6, %r14;
	cvt.rn.f32.u32	%f7, %r13;
	div.approx.f32 	%f8, %f7, %f6;
	mov.f32 	%f9, 0f3E9C61AA;
	cos.approx.ftz.f32 	%f10, %f9;
	sin.approx.ftz.f32 	%f11, %f9;
	div.approx.f32 	%f12, %f11, %f10;
	mul.f32 	%f13, %f12, 0fC0000000;
	mul.f32 	%f14, %f8, %f13;
	div.approx.f32 	%f15, %f14, %f7;
	mul.f32 	%f16, %f14, 0fBF000000;
	fma.rn.f32 	%f17, %f15, %f5, %f16;
	shr.u32 	%r27, %r19, 9;
	or.b32  	%r28, %r27, 1065353216;
	mov.b32 	 %f18, %r28;
	add.f32 	%f19, %f18, 0fBF800000;
	div.u32 	%r29, %r1, %r14;
	cvt.rn.f32.u32	%f20, %r29;
	add.f32 	%f21, %f20, %f19;
	mov.f32 	%f22, 0f80000000;
	div.approx.f32 	%f23, %f22, %f6;
	fma.rn.f32 	%f24, %f23, %f21, %f17;
	st.f32 	[%SP+20], %f24;
	mov.f32 	%f25, 0f00000000;
	div.approx.f32 	%f26, %f25, %f7;
	fma.rn.f32 	%f27, %f26, %f5, %f12;
	div.approx.f32 	%f28, %f13, %f6;
	fma.rn.f32 	%f29, %f28, %f21, %f27;
	st.f32 	[%SP+24], %f29;
	fma.rn.f32 	%f30, %f26, %f5, 0f3F800000;
	div.approx.f32 	%f31, %f25, %f6;
	fma.rn.f32 	%f32, %f31, %f21, %f30;
	st.f32 	[%SP+28], %f32;
	mov.u16 	%rs1, 1;
	cvt.u32.u16	%r30, %rs1;
	add.u64 	%rd4, %SP, 32;
	add.u64 	%rd5, %SP, 0;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd5;
	.param .b32 param3;
	st.param.b32	[param3+0], %r30;
	call.uni 
	_ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	
	//{
	}// Callseq End 0
	setp.ne.s32	%p1, %r2, 0;
	ld.param.u64 	%rd1, [path_trace_param_0];
	ld.f32 	%f1, [%SP+32];
	@%p1 bra 	BB43_2;
	bra.uni 	BB43_1;
BB43_2:
	add.s32 	%r31, %r2, 1;
	cvt.rn.f32.u32	%f33, %r31;
	rcp.approx.f32 	%f34, %f33;
	mul.f32 	%f35, %f34, %f1;
	mov.f32 	%f36, 0f3F800000;
	sub.f32 	%f37, %f36, %f34;
	mul.wide.u32 	%rd6, %r1, 12;
	add.s64 	%rd7, %rd1, %rd6;
	ld.f32 	%f38, [%rd7];
	fma.rn.f32 	%f39, %f38, %f37, %f35;
	ld.f32 	%f40, [%rd7+8];
	ld.f32 	%f41, [%rd7+4];
	or.b64  	%rd9, %rd4, 4;
	ld.f32 	%f42, [%rd9];
	ld.f32 	%f43, [%SP+40];
	st.f32 	[%rd7], %f39;
	mul.f32 	%f44, %f34, %f42;
	fma.rn.f32 	%f45, %f37, %f41, %f44;
	st.f32 	[%rd7+4], %f45;
	mul.f32 	%f46, %f34, %f43;
	fma.rn.f32 	%f47, %f37, %f40, %f46;
	st.f32 	[%rd7+8], %f47;
	bra.uni 	BB43_3;
BB43_1:
	mul.wide.u32 	%rd10, %r1, 12;
	add.s64 	%rd11, %rd1, %rd10;
	st.f32 	[%rd11], %f1;
	or.b64  	%rd13, %rd4, 4;
	ld.f32 	%f48, [%rd13];
	st.f32 	[%rd11+4], %f48;
	ld.f32 	%f49, [%SP+40];
	st.f32 	[%rd11+8], %f49;
BB43_3:
	ret;
}

.weak .func _ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb(
	.param .b64 _ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb_param_0,
	.param .b64 _ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb_param_1,
	.param .b64 _ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb_param_2,
	.param .b32 _ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb_param_3
)                                       // @_ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb
{
	.local .align 8 .b8 	__local_depot44[80];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<3>;
	.reg .s16 	%rs<3>;
	.reg .f32 	%f<29>;
	.reg .s32 	%r<3>;
	.reg .s64 	%rd<22>;

// BB#0:
	mov.u64 	%rd21, __local_depot44;
	cvta.local.u64 	%SP, %rd21;
	add.u64 	%rd6, %SP, 0;
	ld.param.u64 	%rd4, [_ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb_param_1];
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd4;
	call.uni 
	_ZN18simple_intersector9intersectERK3ray, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 1
	ld.param.u8 	%rs1, [_ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb_param_3];
	and.b16  	%rs2, %rs1, 1;
	setp.eq.b16	%p1, %rs2, 1;
	ld.u32 	%r1, [%SP+28];
	setp.lt.u32	%p2, %r1, 8;
	ld.param.u64 	%rd3, [_ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb_param_0];
	@%p2 bra 	BB44_2;
// BB#1:
	mov.u64 	%rd20, 0;
	st.u32 	[%rd3+4], %rd20;
	st.u32 	[%rd3], %rd20;
	mov.u32 	%r2, 0;
	st.u32 	[%rd3+8], %r2;
	bra.uni 	BB44_5;
BB44_2:
	ld.param.u64 	%rd5, [_ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb_param_2];
	mul.wide.u32 	%rd7, %r1, 64;
	mov.u64 	%rd8, _ZL17cornell_materials;
	cvta.const.u64 	%rd9, %rd8;
	add.s64 	%rd2, %rd9, %rd7;
	mov.f32 	%f26, 0f00000000;
	mov.f32 	%f27, %f26;
	mov.f32 	%f28, %f26;
	@!%p1 bra 	BB44_4;
	bra.uni 	BB44_3;
BB44_3:
	cvt.u64.u32	%rd1, %r1;
	shl.b64 	%rd10, %rd1, 6;
	add.s64 	%rd12, %rd8, %rd10;
	ld.const.f32 	%f26, [%rd12+36];
	ld.const.f32 	%f27, [%rd12+32];
	ld.const.f32 	%f28, [%rd12+28];
BB44_4:
	ld.f32 	%f8, [%rd4+20];
	ld.f32 	%f9, [%rd4+16];
	ld.f32 	%f10, [%rd4+12];
	neg.f32 	%f11, %f10;
	st.f32 	[%SP+48], %f11;
	add.u64 	%rd13, %SP, 48;
	or.b64  	%rd14, %rd13, 4;
	neg.f32 	%f12, %f9;
	st.f32 	[%rd14], %f12;
	neg.f32 	%f13, %f8;
	st.f32 	[%SP+56], %f13;
	add.u64 	%rd15, %SP, 32;
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd15;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd13;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd6;
	.param .b64 param3;
	st.param.b64	[param3+0], %rd2;
	.param .b64 param4;
	st.param.b64	[param4+0], %rd5;
	call.uni 
	_ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	
	//{
	}// Callseq End 2
	or.b64  	%rd17, %rd15, 4;
	ld.f32 	%f14, [%rd17];
	ld.f32 	%f15, [%SP+40];
	ld.f32 	%f16, [%SP+32];
	add.u64 	%rd18, %SP, 64;
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd18;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd4;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd6;
	.param .b64 param3;
	st.param.b64	[param3+0], %rd2;
	.param .b64 param4;
	st.param.b64	[param4+0], %rd5;
	call.uni 
	_ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	
	//{
	}// Callseq End 3
	add.f32 	%f17, %f28, %f16;
	ld.f32 	%f18, [%SP+64];
	add.f32 	%f19, %f17, %f18;
	or.b64  	%rd19, %rd18, 4;
	ld.f32 	%f20, [%rd19];
	ld.f32 	%f21, [%SP+72];
	st.f32 	[%rd3], %f19;
	add.f32 	%f22, %f27, %f14;
	add.f32 	%f23, %f22, %f20;
	st.f32 	[%rd3+4], %f23;
	add.f32 	%f24, %f26, %f15;
	add.f32 	%f25, %f24, %f21;
	st.f32 	[%rd3+8], %f25;
BB44_5:
	ret;
}

.weak .func _ZN18simple_intersector9intersectERK3ray(
	.param .b64 _ZN18simple_intersector9intersectERK3ray_param_0,
	.param .b64 _ZN18simple_intersector9intersectERK3ray_param_1
)                                       // @_ZN18simple_intersector9intersectERK3ray
{
	.reg .pred 	%p<16>;
	.reg .f32 	%f<108>;
	.reg .s32 	%r<10>;
	.reg .s64 	%rd<23>;

// BB#0:
	ld.param.u64 	%rd8, [_ZN18simple_intersector9intersectERK3ray_param_1];
	ld.f32 	%f6, [%rd8+8];
	ld.f32 	%f5, [%rd8+4];
	ld.f32 	%f4, [%rd8];
	ld.f32 	%f3, [%rd8+12];
	ld.f32 	%f2, [%rd8+20];
	ld.f32 	%f1, [%rd8+16];
	mov.u64 	%rd9, _ZL15cornell_indices;
	cvta.const.u64 	%rd10, %rd9;
	add.s64 	%rd21, %rd10, 8;
	mov.f32 	%f106, 0f00000000;
	mov.f32 	%f107, 0f7F800000;
	mov.u32 	%r9, 8;
	mov.u64 	%rd22, 0;
	ld.param.u64 	%rd5, [_ZN18simple_intersector9intersectERK3ray_param_0];
	mov.f32 	%f105, %f106;
	mov.f32 	%f104, %f106;
	bra.uni 	BB45_1;
BB45_6:                                 //   in Loop: Header=BB45_1 Depth=1
	mul.f32 	%f80, %f18, %f28;
	fma.rn.f32 	%f81, %f17, %f27, %f80;
	fma.rn.f32 	%f82, %f19, %f29, %f81;
	mul.f32 	%f32, %f26, %f82;
	setp.lt.f32	%p7, %f32, %f107;
	setp.ge.f32	%p8, %f32, 0f38D1B717;
	and.pred  	%p9, %p8, %p7;
	@!%p9 bra 	BB45_10;
	bra.uni 	BB45_7;
BB45_7:                                 //   in Loop: Header=BB45_1 Depth=1
	mul.f32 	%f83, %f12, %f19;
	neg.f32 	%f84, %f83;
	fma.rn.f32 	%f105, %f16, %f17, %f84;
	setp.eq.f32	%p10, %f105, 0f00000000;
	mul.f32 	%f85, %f16, %f18;
	neg.f32 	%f86, %f85;
	fma.rn.f32 	%f106, %f14, %f19, %f86;
	setp.eq.f32	%p11, %f106, 0f00000000;
	and.pred  	%p12, %p11, %p10;
	mul.f32 	%f87, %f14, %f17;
	neg.f32 	%f88, %f87;
	fma.rn.f32 	%f104, %f12, %f18, %f88;
	setp.eq.f32	%p13, %f104, 0f00000000;
	and.pred  	%p14, %p12, %p13;
	@%p14 bra 	BB45_12;
	bra.uni 	BB45_8;
BB45_12:                                //   in Loop: Header=BB45_1 Depth=1
	bra.uni 	BB45_9;
BB45_8:                                 // %_ZNK7vector3IfE7is_nullEv.exit.thread.i
                                        //   in Loop: Header=BB45_1 Depth=1
	mul.f32 	%f89, %f105, %f105;
	fma.rn.f32 	%f90, %f106, %f106, %f89;
	fma.rn.f32 	%f91, %f104, %f104, %f90;
	rsqrt.approx.ftz.f32 	%f92, %f91;
	mul.f32 	%f104, %f104, %f92;
	mul.f32 	%f105, %f105, %f92;
	mul.f32 	%f106, %f106, %f92;
BB45_9:                                 // %_ZNK7vector3IfE10normalizedEv.exit
                                        //   in Loop: Header=BB45_1 Depth=1
	mov.u64 	%rd18, _ZL18cornell_object_map;
	cvta.const.u64 	%rd19, %rd18;
	add.s64 	%rd20, %rd19, %rd22;
	ld.u32 	%r9, [%rd20];
	mov.f32 	%f107, %f32;
	bra.uni 	BB45_10;
BB45_1:                                 // =>This Inner Loop Header: Depth=1
	ld.u32 	%r5, [%rd21];
	mul.wide.u32 	%rd11, %r5, 12;
	mov.u64 	%rd12, _ZL16cornell_vertices;
	add.s64 	%rd13, %rd12, %rd11;
	ld.const.f32 	%f15, [%rd13+8];
	ld.u32 	%r6, [%rd21+-4];
	mul.wide.u32 	%rd14, %r6, 12;
	add.s64 	%rd15, %rd12, %rd14;
	ld.const.f32 	%f48, [%rd15+8];
	sub.f32 	%f19, %f48, %f15;
	ld.const.f32 	%f13, [%rd13+4];
	ld.const.f32 	%f49, [%rd15+4];
	sub.f32 	%f18, %f49, %f13;
	mul.f32 	%f50, %f18, %f2;
	neg.f32 	%f51, %f50;
	fma.rn.f32 	%f20, %f1, %f19, %f51;
	ld.const.f32 	%f11, [%rd13];
	ld.const.f32 	%f52, [%rd15];
	sub.f32 	%f17, %f52, %f11;
	mul.f32 	%f53, %f19, %f3;
	neg.f32 	%f54, %f53;
	fma.rn.f32 	%f21, %f17, %f2, %f54;
	ld.u32 	%r7, [%rd21+-8];
	mul.wide.u32 	%rd16, %r7, 12;
	add.s64 	%rd17, %rd12, %rd16;
	ld.const.f32 	%f55, [%rd17+4];
	sub.f32 	%f14, %f55, %f13;
	mul.f32 	%f56, %f14, %f21;
	ld.const.f32 	%f57, [%rd17];
	sub.f32 	%f12, %f57, %f11;
	fma.rn.f32 	%f58, %f12, %f20, %f56;
	mul.f32 	%f59, %f17, %f1;
	neg.f32 	%f60, %f59;
	fma.rn.f32 	%f22, %f18, %f3, %f60;
	ld.const.f32 	%f61, [%rd17+8];
	sub.f32 	%f16, %f61, %f15;
	fma.rn.f32 	%f23, %f16, %f22, %f58;
	setp.ge.f32	%p1, %f23, 0f00000000;
	mov.f32 	%f100, %f23;
	@%p1 bra 	BB45_3;
// BB#2:                                //   in Loop: Header=BB45_1 Depth=1
	neg.f32 	%f100, %f23;
BB45_3:                                 // %_ZN10const_math3absIfvEET_S1_.exit
                                        //   in Loop: Header=BB45_1 Depth=1
	setp.le.f32	%p2, %f100, 0f3727C5AC;
	@%p2 bra 	BB45_13;
// BB#4:                                //   in Loop: Header=BB45_1 Depth=1
	sub.f32 	%f62, %f5, %f13;
	sub.f32 	%f63, %f6, %f15;
	mul.f32 	%f64, %f14, %f63;
	neg.f32 	%f65, %f64;
	fma.rn.f32 	%f27, %f16, %f62, %f65;
	sub.f32 	%f66, %f4, %f11;
	mul.f32 	%f67, %f16, %f66;
	neg.f32 	%f68, %f67;
	fma.rn.f32 	%f28, %f12, %f63, %f68;
	mul.f32 	%f69, %f1, %f28;
	fma.rn.f32 	%f70, %f3, %f27, %f69;
	mul.f32 	%f71, %f12, %f62;
	neg.f32 	%f72, %f71;
	fma.rn.f32 	%f29, %f14, %f66, %f72;
	fma.rn.f32 	%f73, %f29, %f2, %f70;
	rcp.approx.f32 	%f26, %f23;
	mul.f32 	%f31, %f26, %f73;
	setp.ge.f32	%p3, %f31, 0f00000000;
	mul.f32 	%f74, %f21, %f62;
	fma.rn.f32 	%f75, %f20, %f66, %f74;
	fma.rn.f32 	%f76, %f22, %f63, %f75;
	mul.f32 	%f30, %f26, %f76;
	setp.ge.f32	%p4, %f30, 0f00000000;
	and.pred  	%p5, %p4, %p3;
	@!%p5 bra 	BB45_10;
	bra.uni 	BB45_5;
BB45_5:                                 // %_ZNK7vector3IbE3anyIbvEEbv.exit
                                        //   in Loop: Header=BB45_1 Depth=1
	mov.f32 	%f77, 0f3F800000;
	sub.f32 	%f78, %f77, %f30;
	sub.f32 	%f79, %f78, %f31;
	setp.lt.f32	%p6, %f79, 0f00000000;
	@%p6 bra 	BB45_14;
	bra.uni 	BB45_6;
BB45_14:                                //   in Loop: Header=BB45_1 Depth=1
	bra.uni 	BB45_10;
BB45_13:                                //   in Loop: Header=BB45_1 Depth=1
BB45_10:                                // %_ZNK7vector3IbE3anyIbvEEbv.exit.thread
                                        //   in Loop: Header=BB45_1 Depth=1
	add.s64 	%rd21, %rd21, 12;
	add.s64 	%rd22, %rd22, 4;
	setp.ne.s64	%p15, %rd22, 128;
	@%p15 bra 	BB45_1;
// BB#11:
	fma.rn.f32 	%f93, %f107, %f3, %f4;
	st.f32 	[%rd5], %f93;
	fma.rn.f32 	%f94, %f107, %f1, %f5;
	st.f32 	[%rd5+4], %f94;
	fma.rn.f32 	%f95, %f107, %f2, %f6;
	st.f32 	[%rd5+8], %f95;
	st.f32 	[%rd5+12], %f106;
	st.f32 	[%rd5+16], %f105;
	st.f32 	[%rd5+20], %f104;
	st.f32 	[%rd5+24], %f107;
	st.u32 	[%rd5+28], %r9;
	ret;
}

.weak .func _ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj(
	.param .b64 _ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_0,
	.param .b64 _ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_1,
	.param .b64 _ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_2,
	.param .b64 _ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_3,
	.param .b64 _ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_4
)                                       // @_ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj
{
	.local .align 8 .b8 	__local_depot46[56];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<32>;
	.reg .f32 	%f<131>;
	.reg .s32 	%r<10>;
	.reg .s64 	%rd<12>;

// BB#0:
	mov.u64 	%rd11, __local_depot46;
	cvta.local.u64 	%SP, %rd11;
	ld.param.u64 	%rd1, [_ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_0];
	mov.u64 	%rd6, 0;
	st.u32 	[%rd1+4], %rd6;
	st.u32 	[%rd1], %rd6;
	mov.u32 	%r2, 0;
	st.u32 	[%rd1+8], %r2;
	ld.param.u64 	%rd3, [_ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_2];
	ld.f32 	%f117, [%rd3+16];
	setp.eq.f32	%p1, %f117, 0f00000000;
	ld.f32 	%f118, [%rd3+12];
	setp.eq.f32	%p2, %f118, 0f00000000;
	and.pred  	%p3, %p2, %p1;
	ld.f32 	%f116, [%rd3+20];
	setp.eq.f32	%p4, %f116, 0f00000000;
	and.pred  	%p5, %p3, %p4;
	ld.param.u64 	%rd5, [_ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_4];
	ld.param.u64 	%rd4, [_ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_3];
	ld.param.u64 	%rd2, [_ZN18simple_path_tracer27compute_direct_illuminationERK7vector3IfERKN18simple_intersector12intersectionERK8materialRj_param_1];
	@%p5 bra 	BB46_16;
	bra.uni 	BB46_1;
BB46_16:
	bra.uni 	BB46_2;
BB46_1:                                 // %_ZNK7vector3IfE7is_nullEv.exit.thread.i6
	mul.f32 	%f51, %f117, %f117;
	fma.rn.f32 	%f52, %f118, %f118, %f51;
	fma.rn.f32 	%f53, %f116, %f116, %f52;
	rsqrt.approx.ftz.f32 	%f54, %f53;
	mul.f32 	%f116, %f116, %f54;
	mul.f32 	%f117, %f117, %f54;
	mul.f32 	%f118, %f118, %f54;
BB46_2:                                 // %_ZNK7vector3IfE10normalizedEv.exit7
	ld.f32 	%f120, [%rd2+4];
	setp.eq.f32	%p6, %f120, 0f00000000;
	ld.f32 	%f121, [%rd2];
	setp.eq.f32	%p7, %f121, 0f00000000;
	and.pred  	%p8, %p7, %p6;
	ld.f32 	%f119, [%rd2+8];
	setp.eq.f32	%p9, %f119, 0f00000000;
	and.pred  	%p10, %p8, %p9;
	@%p10 bra 	BB46_17;
	bra.uni 	BB46_3;
BB46_17:
	bra.uni 	BB46_4;
BB46_3:                                 // %_ZNK7vector3IfE7is_nullEv.exit.thread.i15
	mul.f32 	%f55, %f120, %f120;
	fma.rn.f32 	%f56, %f121, %f121, %f55;
	fma.rn.f32 	%f57, %f119, %f119, %f56;
	rsqrt.approx.ftz.f32 	%f58, %f57;
	mul.f32 	%f119, %f119, %f58;
	mul.f32 	%f120, %f120, %f58;
	mul.f32 	%f121, %f121, %f58;
BB46_4:                                 // %_ZNK7vector3IfE10normalizedEv.exit16
	ld.u32 	%r3, [%rd5];
	mul.lo.s32 	%r4, %r3, 282475249;
	st.u32 	[%rd5], %r4;
	ld.f32 	%f59, [%rd3+8];
	ld.f32 	%f60, [%rd3+4];
	ld.f32 	%f61, [%rd3];
	st.f32 	[%SP+0], %f61;
	add.u64 	%rd7, %SP, 0;
	or.b64  	%rd8, %rd7, 4;
	st.f32 	[%rd8], %f60;
	st.f32 	[%SP+8], %f59;
	mov.f32 	%f62, 0f425B3333;
	sub.f32 	%f123, %f62, %f60;
	shr.u32 	%r5, %r4, 9;
	or.b32  	%r6, %r5, 1065353216;
	mov.b32 	 %f63, %r6;
	add.f32 	%f64, %f63, 0fBF800000;
	fma.rn.f32 	%f65, %f64, 0fC1500000, 0f42093333;
	sub.f32 	%f122, %f65, %f61;
	mul.f32 	%f66, %f122, %f122;
	fma.rn.f32 	%f67, %f123, %f123, %f66;
	mul.lo.s32 	%r7, %r3, 16807;
	shr.u32 	%r8, %r7, 9;
	or.b32  	%r9, %r8, 1065353216;
	mov.b32 	 %f68, %r9;
	add.f32 	%f69, %f68, 0fBF800000;
	fma.rn.f32 	%f70, %f69, 0f41280000, 0f41B5999A;
	sub.f32 	%f124, %f70, %f59;
	fma.rn.f32 	%f22, %f124, %f124, %f67;
	setp.gt.f32	%p11, %f22, 0f38D1B717;
	setp.eq.f32	%p12, %f123, 0f00000000;
	setp.eq.f32	%p13, %f122, 0f00000000;
	and.pred  	%p14, %p13, %p12;
	setp.eq.f32	%p15, %f124, 0f00000000;
	and.pred  	%p16, %p14, %p15;
	@%p16 bra 	BB46_18;
	bra.uni 	BB46_5;
BB46_18:
	bra.uni 	BB46_6;
BB46_5:                                 // %_ZNK7vector3IfE7is_nullEv.exit.thread.i10
	rsqrt.approx.ftz.f32 	%f71, %f22;
	mul.f32 	%f124, %f124, %f71;
	mul.f32 	%f123, %f123, %f71;
	mul.f32 	%f122, %f122, %f71;
BB46_6:                                 // %_ZNK7vector3IfE10normalizedEv.exit11
	selp.f32	%f23, %f22, 0f38D1B717, %p11;
	st.f32 	[%SP+12], %f122;
	st.f32 	[%SP+16], %f123;
	st.f32 	[%SP+20], %f124;
	add.u64 	%rd9, %SP, 24;
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd7;
	call.uni 
	_ZN18simple_intersector9intersectERK3ray, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 4
	ld.u32 	%r1, [%SP+52];
	setp.gt.u32	%p17, %r1, 7;
	@%p17 bra 	BB46_8;
// BB#7:
	sqrt.rn.ftz.f32 	%f72, %f23;
	add.f32 	%f73, %f72, 0fB8D1B717;
	ld.f32 	%f74, [%SP+48];
	setp.ge.f32	%p18, %f74, %f73;
	setp.eq.s32	%p19, %r1, 1;
	or.pred  	%p20, %p18, %p19;
	@!%p20 bra 	BB46_15;
	bra.uni 	BB46_8;
BB46_8:
	mul.f32 	%f75, %f118, %f122;
	fma.rn.f32 	%f76, %f117, %f123, %f75;
	fma.rn.f32 	%f77, %f116, %f124, %f76;
	setp.gt.f32	%p21, %f77, 0f00000000;
	selp.f32	%f32, %f77, 0f00000000, %p21;
	setp.gt.f32	%p22, %f123, 0f00000000;
	selp.f32	%f31, %f123, 0f00000000, %p22;
	ld.f32 	%f128, [%rd4+48];
	ld.f32 	%f129, [%rd4+44];
	ld.f32 	%f130, [%rd4+40];
	rcp.approx.f32 	%f30, %f23;
	ld.f32 	%f78, [%rd4+12];
	setp.ne.f32	%p23, %f78, 0f00000000;
	@%p23 bra 	BB46_11;
// BB#9:
	ld.f32 	%f79, [%rd4+16];
	setp.ne.f32	%p24, %f79, 0f00000000;
	@%p24 bra 	BB46_11;
// BB#10:                               // %_ZNK7vector3IfE7is_nullEv.exit
	ld.f32 	%f80, [%rd4+20];
	setp.eq.f32	%p25, %f80, 0f00000000;
	@%p25 bra 	BB46_20;
	bra.uni 	BB46_11;
BB46_20:
	bra.uni 	BB46_14;
BB46_11:                                // %_ZNK7vector3IfE7is_nullEv.exit.thread
	mul.f32 	%f81, %f117, %f123;
	neg.f32 	%f82, %f81;
	neg.f32 	%f83, %f122;
	fma.rn.f32 	%f84, %f118, %f83, %f82;
	neg.f32 	%f85, %f116;
	fma.rn.f32 	%f86, %f85, %f124, %f84;
	add.f32 	%f87, %f86, %f86;
	neg.f32 	%f88, %f123;
	neg.f32 	%f89, %f117;
	fma.rn.f32 	%f126, %f89, %f87, %f88;
	setp.eq.f32	%p26, %f126, 0f00000000;
	neg.f32 	%f90, %f118;
	fma.rn.f32 	%f127, %f90, %f87, %f83;
	setp.eq.f32	%p27, %f127, 0f00000000;
	and.pred  	%p28, %p27, %p26;
	neg.f32 	%f91, %f124;
	fma.rn.f32 	%f125, %f85, %f87, %f91;
	setp.eq.f32	%p29, %f125, 0f00000000;
	and.pred  	%p30, %p28, %p29;
	@%p30 bra 	BB46_19;
	bra.uni 	BB46_12;
BB46_19:
	bra.uni 	BB46_13;
BB46_12:                                // %_ZNK7vector3IfE7is_nullEv.exit.thread.i
	mul.f32 	%f92, %f126, %f126;
	fma.rn.f32 	%f93, %f127, %f127, %f92;
	fma.rn.f32 	%f94, %f125, %f125, %f93;
	rsqrt.approx.ftz.f32 	%f95, %f94;
	mul.f32 	%f125, %f125, %f95;
	mul.f32 	%f126, %f126, %f95;
	mul.f32 	%f127, %f127, %f95;
BB46_13:                                // %_ZNK7vector3IfE10normalizedEv.exit
	mul.f32 	%f96, %f121, %f127;
	fma.rn.f32 	%f97, %f120, %f126, %f96;
	fma.rn.f32 	%f98, %f119, %f125, %f97;
	setp.gt.f32	%p31, %f98, 0f00000000;
	selp.f32	%f99, %f98, 0f00000000, %p31;
	lg2.approx.ftz.f32 	%f100, %f99;
	ld.f32 	%f101, [%rd4+24];
	mul.f32 	%f102, %f101, %f100;
	ex2.approx.ftz.f32 	%f103, %f102;
	ld.f32 	%f104, [%rd4+60];
	fma.rn.f32 	%f128, %f103, %f104, %f128;
	ld.f32 	%f105, [%rd4+56];
	fma.rn.f32 	%f129, %f103, %f105, %f129;
	ld.f32 	%f106, [%rd4+52];
	fma.rn.f32 	%f130, %f103, %f106, %f130;
BB46_14:
	mul.f32 	%f107, %f31, %f32;
	mov.f32 	%f108, 0f46919080;
	sqrt.rz.ftz.f32 	%f109, %f108;
	mul.f32 	%f110, %f107, %f109;
	mul.f32 	%f111, %f30, %f110;
	mul.f32 	%f112, %f111, 0f41700000;
	mul.f32 	%f113, %f130, %f112;
	st.f32 	[%rd1], %f113;
	mul.f32 	%f114, %f129, %f112;
	st.f32 	[%rd1+4], %f114;
	mul.f32 	%f115, %f128, %f112;
	st.f32 	[%rd1+8], %f115;
BB46_15:
	ret;
}

.weak .func _ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj(
	.param .b64 _ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_0,
	.param .b64 _ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_1,
	.param .b64 _ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_2,
	.param .b64 _ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_3,
	.param .b64 _ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_4
)                                       // @_ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj
{
	.local .align 8 .b8 	__local_depot47[160];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<43>;
	.reg .s16 	%rs<3>;
	.reg .f32 	%f<239>;
	.reg .s32 	%r<22>;
	.reg .s64 	%rd<29>;

// BB#0:
	mov.u64 	%rd28, __local_depot47;
	cvta.local.u64 	%SP, %rd28;
	ld.param.u64 	%rd5, [_ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_1];
	ld.f32 	%f4, [%rd5+16];
	ld.param.u64 	%rd2, [_ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_2];
	ld.f32 	%f10, [%rd2+16];
	mul.f32 	%f81, %f10, %f4;
	ld.f32 	%f2, [%rd5+12];
	ld.f32 	%f11, [%rd2+12];
	fma.rn.f32 	%f82, %f11, %f2, %f81;
	ld.f32 	%f6, [%rd5+20];
	ld.f32 	%f12, [%rd2+20];
	fma.rn.f32 	%f83, %f12, %f6, %f82;
	setp.le.f32	%p1, %f83, 0f00000000;
	ld.param.u64 	%rd4, [_ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_4];
	ld.param.u64 	%rd3, [_ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_3];
	ld.param.u64 	%rd1, [_ZN18simple_path_tracer29compute_indirect_illuminationILj0EEE7vector3IfERK3rayRKN18simple_intersector12intersectionERK8materialRj_param_0];
	@%p1 bra 	BB47_2;
// BB#1:
	neg.f32 	%f11, %f11;
	st.f32 	[%SP+0], %f11;
	add.u64 	%rd8, %SP, 0;
	or.b64  	%rd9, %rd8, 4;
	neg.f32 	%f10, %f10;
	st.f32 	[%rd9], %f10;
	neg.f32 	%f12, %f12;
	bra.uni 	BB47_3;
BB47_2:
	st.f32 	[%SP+0], %f11;
	add.u64 	%rd6, %SP, 0;
	or.b64  	%rd7, %rd6, 4;
	st.f32 	[%rd7], %f10;
BB47_3:
	st.f32 	[%SP+8], %f12;
	ld.f32 	%f84, [%rd3+8];
	ld.f32 	%f85, [%rd3];
	ld.f32 	%f86, [%rd3+4];
	ld.f32 	%f87, [%rd3+20];
	ld.f32 	%f88, [%rd3+12];
	ld.f32 	%f89, [%rd3+16];
	ld.u32 	%r1, [%rd4];
	mul.lo.s32 	%r2, %r1, 16807;
	st.u32 	[%rd4], %r2;
	mul.f32 	%f92, %f86, 0f3F34EA4B;
	fma.rn.f32 	%f93, %f85, 0f3E6353F8, %f92;
	fma.rn.f32 	%f13, %f84, 0f3D9205BC, %f93;
	shr.u32 	%r3, %r2, 9;
	or.b32  	%r4, %r3, 1065353216;
	mov.b32 	 %f94, %r4;
	add.f32 	%f15, %f94, 0fBF800000;
	setp.ge.f32	%p2, %f15, %f13;
	@%p2 bra 	BB47_10;
// BB#4:
	add.u64 	%rd20, %SP, 16;
	add.u64 	%rd21, %SP, 0;
	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd20;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd21;
	call.uni 
	_ZN18simple_path_tracer16get_local_systemERK7vector3IfE, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 7
	ld.u32 	%r14, [%rd4];
	mul.lo.s32 	%r15, %r14, 282475249;
	st.u32 	[%rd4], %r15;
	shr.u32 	%r16, %r15, 9;
	or.b32  	%r17, %r16, 1065353216;
	mov.b32 	 %f170, %r17;
	mov.f32 	%f171, 0f40000000;
	sub.f32 	%f172, %f171, %f170;
	sqrt.rn.ftz.f32 	%f173, %f172;
	mul.lo.s32 	%r18, %r14, 16807;
	shr.u32 	%r19, %r18, 9;
	or.b32  	%r20, %r19, 1065353216;
	mov.b32 	 %f174, %r20;
	add.f32 	%f175, %f174, 0fBF800000;
	mul.f32 	%f176, %f175, 0f40C90FDB;
	cos.approx.ftz.f32 	%f177, %f176;
	mul.f32 	%f223, %f173, %f177;
	setp.eq.f32	%p27, %f223, 0f00000000;
	add.f32 	%f178, %f170, 0fBF800000;
	sqrt.rn.ftz.f32 	%f16, %f178;
	setp.eq.f32	%p28, %f16, 0f00000000;
	and.pred  	%p29, %p27, %p28;
	sin.approx.ftz.f32 	%f179, %f176;
	mul.f32 	%f221, %f173, %f179;
	setp.eq.f32	%p30, %f221, 0f00000000;
	and.pred  	%p31, %p29, %p30;
	@%p31 bra 	BB47_24;
	bra.uni 	BB47_5;
BB47_24:
	mov.f32 	%f222, %f16;
	bra.uni 	BB47_6;
BB47_10:
	mul.f32 	%f90, %f89, 0f3F34EA4B;
	fma.rn.f32 	%f91, %f88, 0f3E6353F8, %f90;
	fma.rn.f32 	%f14, %f87, 0f3D9205BC, %f91;
	add.f32 	%f96, %f13, %f14;
	setp.ge.f32	%p3, %f15, %f96;
	@%p3 bra 	BB47_11;
// BB#12:
	mul.f32 	%f97, %f10, %f4;
	fma.rn.f32 	%f98, %f11, %f2, %f97;
	fma.rn.f32 	%f99, %f12, %f6, %f98;
	add.f32 	%f100, %f99, %f99;
	neg.f32 	%f101, %f10;
	fma.rn.f32 	%f228, %f101, %f100, %f4;
	setp.eq.f32	%p4, %f228, 0f00000000;
	neg.f32 	%f102, %f11;
	fma.rn.f32 	%f227, %f102, %f100, %f2;
	setp.eq.f32	%p5, %f227, 0f00000000;
	and.pred  	%p6, %p5, %p4;
	neg.f32 	%f103, %f12;
	fma.rn.f32 	%f229, %f103, %f100, %f6;
	setp.eq.f32	%p7, %f229, 0f00000000;
	and.pred  	%p8, %p6, %p7;
	@%p8 bra 	BB47_26;
	bra.uni 	BB47_13;
BB47_26:
	bra.uni 	BB47_14;
BB47_5:                                 // %_ZNK7vector3IfE7is_nullEv.exit.thread.i.i
	mul.f32 	%f180, %f223, %f223;
	fma.rn.f32 	%f181, %f16, %f16, %f180;
	fma.rn.f32 	%f182, %f221, %f221, %f181;
	rsqrt.approx.ftz.f32 	%f183, %f182;
	mul.f32 	%f221, %f221, %f183;
	mul.f32 	%f222, %f16, %f183;
	mul.f32 	%f223, %f223, %f183;
BB47_6:                                 // %_ZN7vector3IfE9normalizeEv.exit.i
	mul.f32 	%f184, %f222, %f11;
	ld.f32 	%f185, [%SP+16];
	fma.rn.f32 	%f186, %f223, %f185, %f184;
	ld.f32 	%f187, [%SP+28];
	fma.rn.f32 	%f226, %f221, %f187, %f186;
	setp.eq.f32	%p32, %f226, 0f00000000;
	mul.f32 	%f188, %f222, %f10;
	or.b64  	%rd23, %rd20, 4;
	ld.f32 	%f189, [%rd23];
	fma.rn.f32 	%f190, %f223, %f189, %f188;
	ld.f32 	%f191, [%SP+32];
	fma.rn.f32 	%f225, %f221, %f191, %f190;
	setp.eq.f32	%p33, %f225, 0f00000000;
	and.pred  	%p34, %p32, %p33;
	mul.f32 	%f192, %f222, %f12;
	ld.f32 	%f193, [%SP+24];
	fma.rn.f32 	%f194, %f223, %f193, %f192;
	ld.f32 	%f195, [%SP+36];
	fma.rn.f32 	%f224, %f221, %f195, %f194;
	setp.eq.f32	%p35, %f224, 0f00000000;
	and.pred  	%p36, %p34, %p35;
	@%p36 bra 	BB47_25;
	bra.uni 	BB47_7;
BB47_25:
	bra.uni 	BB47_8;
BB47_11:
	mov.f32 	%f236, 0f00000000;
	mov.f32 	%f237, %f236;
	mov.f32 	%f238, %f236;
	bra.uni 	BB47_22;
BB47_7:                                 // %_ZNK7vector3IfE7is_nullEv.exit.thread.i3.i
	mul.f32 	%f196, %f225, %f225;
	fma.rn.f32 	%f197, %f226, %f226, %f196;
	fma.rn.f32 	%f198, %f224, %f224, %f197;
	rsqrt.approx.ftz.f32 	%f199, %f198;
	mul.f32 	%f224, %f224, %f199;
	mul.f32 	%f225, %f225, %f199;
	mul.f32 	%f226, %f226, %f199;
BB47_8:                                 // %_ZN18simple_path_tracer13transform_dirER7vector3IfERKS1_S4_S4_.exit
	mul.f32 	%f200, %f225, %f10;
	fma.rn.f32 	%f201, %f226, %f11, %f200;
	fma.rn.f32 	%f202, %f224, %f12, %f201;
	setp.gt.f32	%p37, %f202, 0f00000000;
	selp.f32	%f203, %f202, 0f00000000, %p37;
	ld.f32 	%f204, [%rd3+44];
	mul.f32 	%f237, %f204, %f203;
	setp.gt.f32	%p38, %f237, 0f00000000;
	ld.f32 	%f205, [%rd3+40];
	mul.f32 	%f238, %f205, %f203;
	setp.gt.f32	%p39, %f238, 0f00000000;
	or.pred  	%p40, %p39, %p38;
	ld.f32 	%f206, [%rd3+48];
	mul.f32 	%f236, %f206, %f203;
	setp.gt.f32	%p41, %f236, 0f00000000;
	or.pred  	%p42, %p40, %p41;
	@!%p42 bra 	BB47_22;
	bra.uni 	BB47_9;
BB47_9:
	ld.f32 	%f207, [%rd2];
	st.f32 	[%SP+56], %f207;
	add.u64 	%rd24, %SP, 56;
	or.b64  	%rd25, %rd24, 4;
	ld.f32 	%f208, [%rd2+4];
	st.f32 	[%rd25], %f208;
	ld.f32 	%f209, [%rd2+8];
	st.f32 	[%SP+64], %f209;
	st.f32 	[%SP+68], %f226;
	st.f32 	[%SP+72], %f225;
	st.f32 	[%SP+76], %f224;
	mov.u16 	%rs2, 0;
	cvt.u32.u16	%r21, %rs2;
	add.u64 	%rd26, %SP, 40;
	// Callseq Start 8
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd26;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd24;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd4;
	.param .b32 param3;
	st.param.b32	[param3+0], %r21;
	call.uni 
	_ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	
	//{
	}// Callseq End 8
	mul.f32 	%f210, %f16, 0f3EA2F983;
	mul.f32 	%f211, %f13, %f210;
	ld.f32 	%f212, [%SP+48];
	mul.f32 	%f213, %f236, %f212;
	div.approx.f32 	%f236, %f213, %f211;
	or.b64  	%rd27, %rd26, 4;
	ld.f32 	%f214, [%rd27];
	mul.f32 	%f215, %f237, %f214;
	div.approx.f32 	%f237, %f215, %f211;
	ld.f32 	%f216, [%SP+40];
	mul.f32 	%f217, %f238, %f216;
	div.approx.f32 	%f238, %f217, %f211;
	bra.uni 	BB47_22;
BB47_13:                                // %_ZNK7vector3IfE7is_nullEv.exit.thread.i
	mul.f32 	%f104, %f228, %f228;
	fma.rn.f32 	%f105, %f227, %f227, %f104;
	fma.rn.f32 	%f106, %f229, %f229, %f105;
	rsqrt.approx.ftz.f32 	%f107, %f106;
	mul.f32 	%f229, %f229, %f107;
	mul.f32 	%f228, %f228, %f107;
	mul.f32 	%f227, %f227, %f107;
BB47_14:                                // %_ZNK7vector3IfE10normalizedEv.exit
	st.f32 	[%SP+80], %f227;
	add.u64 	%rd10, %SP, 80;
	or.b64  	%rd11, %rd10, 4;
	st.f32 	[%rd11], %f228;
	st.f32 	[%SP+88], %f229;
	add.u64 	%rd12, %SP, 96;
	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd12;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd10;
	call.uni 
	_ZN18simple_path_tracer16get_local_systemERK7vector3IfE, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 5
	ld.u32 	%r5, [%rd4];
	mul.lo.s32 	%r6, %r5, 282475249;
	st.u32 	[%rd4], %r6;
	ld.f32 	%f49, [%rd3+24];
	add.f32 	%f50, %f49, 0f3F800000;
	rcp.approx.f32 	%f108, %f50;
	shr.u32 	%r7, %r6, 9;
	or.b32  	%r8, %r7, 1065353216;
	mov.b32 	 %f109, %r8;
	add.f32 	%f110, %f109, 0fBF800000;
	lg2.approx.ftz.f32 	%f111, %f110;
	mul.f32 	%f112, %f108, %f111;
	ex2.approx.ftz.f32 	%f51, %f112;
	setp.eq.f32	%p9, %f51, 0f00000000;
	mul.f32 	%f52, %f51, %f51;
	mov.f32 	%f113, 0f3F800000;
	sub.f32 	%f114, %f113, %f52;
	sqrt.rn.ftz.f32 	%f115, %f114;
	mul.lo.s32 	%r9, %r5, 16807;
	shr.u32 	%r10, %r9, 9;
	or.b32  	%r11, %r10, 1065353216;
	mov.b32 	 %f116, %r11;
	add.f32 	%f117, %f116, 0fBF800000;
	mul.f32 	%f118, %f117, 0f40C90FDB;
	cos.approx.ftz.f32 	%f119, %f118;
	mul.f32 	%f232, %f115, %f119;
	setp.eq.f32	%p10, %f232, 0f00000000;
	and.pred  	%p11, %p10, %p9;
	sin.approx.ftz.f32 	%f120, %f118;
	mul.f32 	%f230, %f115, %f120;
	setp.eq.f32	%p12, %f230, 0f00000000;
	and.pred  	%p13, %p11, %p12;
	@%p13 bra 	BB47_27;
	bra.uni 	BB47_15;
BB47_27:
	mov.f32 	%f231, %f51;
	bra.uni 	BB47_16;
BB47_15:                                // %_ZNK7vector3IfE7is_nullEv.exit.thread.i.i9
	fma.rn.f32 	%f121, %f232, %f232, %f52;
	fma.rn.f32 	%f122, %f230, %f230, %f121;
	rsqrt.approx.ftz.f32 	%f123, %f122;
	mul.f32 	%f230, %f230, %f123;
	mul.f32 	%f231, %f51, %f123;
	mul.f32 	%f232, %f232, %f123;
BB47_16:                                // %_ZN7vector3IfE9normalizeEv.exit.i12
	mul.f32 	%f124, %f231, %f227;
	ld.f32 	%f125, [%SP+96];
	fma.rn.f32 	%f126, %f232, %f125, %f124;
	ld.f32 	%f127, [%SP+108];
	fma.rn.f32 	%f235, %f230, %f127, %f126;
	setp.eq.f32	%p14, %f235, 0f00000000;
	mul.f32 	%f128, %f231, %f228;
	or.b64  	%rd14, %rd12, 4;
	ld.f32 	%f129, [%rd14];
	fma.rn.f32 	%f130, %f232, %f129, %f128;
	ld.f32 	%f131, [%SP+112];
	fma.rn.f32 	%f234, %f230, %f131, %f130;
	setp.eq.f32	%p15, %f234, 0f00000000;
	and.pred  	%p16, %p14, %p15;
	mul.f32 	%f132, %f231, %f229;
	ld.f32 	%f133, [%SP+104];
	fma.rn.f32 	%f134, %f232, %f133, %f132;
	ld.f32 	%f135, [%SP+116];
	fma.rn.f32 	%f233, %f230, %f135, %f134;
	setp.eq.f32	%p17, %f233, 0f00000000;
	and.pred  	%p18, %p16, %p17;
	@%p18 bra 	BB47_28;
	bra.uni 	BB47_17;
BB47_28:
	bra.uni 	BB47_18;
BB47_17:                                // %_ZNK7vector3IfE7is_nullEv.exit.thread.i3.i13
	mul.f32 	%f136, %f234, %f234;
	fma.rn.f32 	%f137, %f235, %f235, %f136;
	fma.rn.f32 	%f138, %f233, %f233, %f137;
	rsqrt.approx.ftz.f32 	%f139, %f138;
	mul.f32 	%f233, %f233, %f139;
	mul.f32 	%f234, %f234, %f139;
	mul.f32 	%f235, %f235, %f139;
BB47_18:                                // %_ZN18simple_path_tracer13transform_dirER7vector3IfERKS1_S4_S4_.exit14
	mul.f32 	%f144, %f234, %f10;
	fma.rn.f32 	%f145, %f235, %f11, %f144;
	fma.rn.f32 	%f71, %f233, %f12, %f145;
	setp.gt.f32	%p19, %f71, 0f00000000;
	@%p19 bra 	BB47_20;
	bra.uni 	BB47_19;
BB47_20:
	mul.f32 	%f146, %f234, %f228;
	fma.rn.f32 	%f147, %f235, %f227, %f146;
	fma.rn.f32 	%f148, %f233, %f229, %f147;
	setp.gt.f32	%p20, %f148, 0f00000000;
	selp.f32	%f149, %f148, 0f00000000, %p20;
	lg2.approx.ftz.f32 	%f150, %f149;
	mul.f32 	%f151, %f49, %f150;
	ex2.approx.ftz.f32 	%f152, %f151;
	ld.f32 	%f153, [%rd3+56];
	mul.f32 	%f154, %f153, %f152;
	selp.f32	%f155, %f71, 0f00000000, %p19;
	mul.f32 	%f237, %f155, %f154;
	setp.gt.f32	%p22, %f237, 0f00000000;
	ld.f32 	%f156, [%rd3+52];
	mul.f32 	%f157, %f156, %f152;
	mul.f32 	%f238, %f155, %f157;
	setp.gt.f32	%p23, %f238, 0f00000000;
	or.pred  	%p24, %p23, %p22;
	ld.f32 	%f158, [%rd3+60];
	mul.f32 	%f159, %f158, %f152;
	mul.f32 	%f236, %f155, %f159;
	setp.gt.f32	%p25, %f236, 0f00000000;
	or.pred  	%p26, %p24, %p25;
	@!%p26 bra 	BB47_22;
	bra.uni 	BB47_21;
BB47_21:
	lg2.approx.ftz.f32 	%f140, %f51;
	mul.f32 	%f141, %f49, %f140;
	ex2.approx.ftz.f32 	%f142, %f141;
	mul.f32 	%f143, %f50, %f142;
	mul.f32 	%f70, %f143, 0f3E22F983;
	ld.f32 	%f160, [%rd2];
	st.f32 	[%SP+136], %f160;
	add.u64 	%rd16, %SP, 136;
	or.b64  	%rd17, %rd16, 4;
	ld.f32 	%f161, [%rd2+4];
	st.f32 	[%rd17], %f161;
	ld.f32 	%f162, [%rd2+8];
	st.f32 	[%SP+144], %f162;
	st.f32 	[%SP+148], %f235;
	st.f32 	[%SP+152], %f234;
	st.f32 	[%SP+156], %f233;
	mov.u16 	%rs1, 0;
	cvt.u32.u16	%r13, %rs1;
	add.u64 	%rd18, %SP, 120;
	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd18;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd16;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd4;
	.param .b32 param3;
	st.param.b32	[param3+0], %r13;
	call.uni 
	_ZN18simple_path_tracer16compute_radianceILj0ELi0EEE7vector3IfERK3rayRjb, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	
	//{
	}// Callseq End 6
	mul.f32 	%f163, %f14, %f70;
	ld.f32 	%f164, [%SP+128];
	mul.f32 	%f165, %f236, %f164;
	div.approx.f32 	%f236, %f165, %f163;
	or.b64  	%rd19, %rd18, 4;
	ld.f32 	%f166, [%rd19];
	mul.f32 	%f167, %f237, %f166;
	div.approx.f32 	%f237, %f167, %f163;
	ld.f32 	%f168, [%SP+120];
	mul.f32 	%f169, %f238, %f168;
	div.approx.f32 	%f238, %f169, %f163;
BB47_22:
	st.f32 	[%rd1], %f238;
	st.f32 	[%rd1+4], %f237;
	st.f32 	[%rd1+8], %f236;
BB47_23:
	ret;
BB47_19:
	mov.u64 	%rd15, 0;
	st.u32 	[%rd1+4], %rd15;
	st.u32 	[%rd1], %rd15;
	mov.u32 	%r12, 0;
	st.u32 	[%rd1+8], %r12;
	bra.uni 	BB47_23;
}

.weak .func _ZN18simple_path_tracer16get_local_systemERK7vector3IfE(
	.param .b64 _ZN18simple_path_tracer16get_local_systemERK7vector3IfE_param_0,
	.param .b64 _ZN18simple_path_tracer16get_local_systemERK7vector3IfE_param_1
)                                       // @_ZN18simple_path_tracer16get_local_systemERK7vector3IfE
{
	.local .align 8 .b8 	__local_depot48[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<20>;
	.reg .f32 	%f<69>;
	.reg .s32 	%r<2>;
	.reg .s64 	%rd<15>;

// BB#0:
	mov.u64 	%rd14, __local_depot48;
	cvta.local.u64 	%SP, %rd14;
	ld.param.u64 	%rd4, [_ZN18simple_path_tracer16get_local_systemERK7vector3IfE_param_1];
	ld.f32 	%f1, [%rd4];
	setp.ge.f32	%p1, %f1, 0f00000000;
	ld.param.u64 	%rd3, [_ZN18simple_path_tracer16get_local_systemERK7vector3IfE_param_0];
	mov.f32 	%f57, %f1;
	@%p1 bra 	BB48_2;
// BB#1:
	neg.f32 	%f57, %f1;
BB48_2:                                 // %_ZN10const_math3absIfvEET_S1_.exit
	ld.f32 	%f4, [%rd4+4];
	setp.ge.f32	%p2, %f4, 0f00000000;
	mov.f32 	%f58, %f4;
	@%p2 bra 	BB48_4;
// BB#3:
	neg.f32 	%f58, %f4;
BB48_4:                                 // %_ZN10const_math3absIfvEET_S1_.exit9
	mov.f32 	%f59, %f1;
	@%p1 bra 	BB48_6;
// BB#5:
	neg.f32 	%f59, %f1;
BB48_6:                                 // %_ZN10const_math3absIfvEET_S1_.exit8
	mov.f32 	%f60, %f4;
	@%p2 bra 	BB48_8;
// BB#7:
	neg.f32 	%f60, %f4;
BB48_8:                                 // %_ZN10const_math3absIfvEET_S1_.exit7
	setp.le.f32	%p3, %f57, %f58;
	setp.gt.f32	%p6, %f59, %f60;
	mov.f32 	%f61, %f1;
	@%p1 bra 	BB48_10;
// BB#9:
	neg.f32 	%f61, %f1;
BB48_10:                                // %_ZN10const_math3absIfvEET_S1_.exit6
	selp.u64	%rd1, 1, 0, %p3;
	selp.u64	%rd2, 1, 0, %p6;
	mov.f32 	%f62, %f4;
	@%p2 bra 	BB48_12;
// BB#11:
	neg.f32 	%f62, %f4;
BB48_12:                                // %_ZN10const_math3absIfvEET_S1_.exit5
	shl.b64 	%rd5, %rd1, 2;
	add.s64 	%rd6, %rd4, %rd5;
	ld.f32 	%f35, [%rd6];
	ld.f32 	%f15, [%rd4+8];
	mov.u32 	%r1, 0;
	st.u32 	[%SP+0], %r1;
	add.u64 	%rd7, %SP, 0;
	or.b64  	%rd8, %rd7, 4;
	st.u32 	[%rd8], %r1;
	setp.gt.f32	%p9, %f61, %f62;
	selp.f32	%f36, 0fBF800000, 0f3F800000, %p9;
	mul.f32 	%f37, %f36, %f15;
	mul.f32 	%f38, %f15, %f15;
	fma.rn.f32 	%f39, %f35, %f35, %f38;
	rcp.approx.f32 	%f40, %f39;
	mul.f32 	%f41, %f40, %f37;
	or.b64  	%rd9, %rd7, %rd5;
	st.f32 	[%rd9], %f41;
	shl.b64 	%rd10, %rd2, 2;
	or.b64  	%rd11, %rd7, %rd10;
	st.u32 	[%rd11], %r1;
	mul.f32 	%f42, %f36, %f35;
	mul.f32 	%f16, %f40, %f42;
	neg.f32 	%f65, %f16;
	st.f32 	[%SP+8], %f65;
	setp.eq.f32	%p10, %f16, 0f80000000;
	ld.f32 	%f64, [%rd8];
	setp.eq.f32	%p11, %f64, 0f00000000;
	ld.f32 	%f63, [%SP+0];
	setp.eq.f32	%p12, %f63, 0f00000000;
	and.pred  	%p13, %p12, %p11;
	and.pred  	%p14, %p13, %p10;
	@%p14 bra 	BB48_17;
	bra.uni 	BB48_13;
BB48_17:
	bra.uni 	BB48_14;
BB48_13:                                // %_ZNK7vector3IfE7is_nullEv.exit.thread.i3
	mul.f32 	%f43, %f64, %f64;
	fma.rn.f32 	%f44, %f63, %f63, %f43;
	fma.rn.f32 	%f45, %f16, %f16, %f44;
	rsqrt.approx.ftz.f32 	%f46, %f45;
	mul.f32 	%f63, %f63, %f46;
	st.f32 	[%SP+0], %f63;
	mul.f32 	%f64, %f64, %f46;
	st.f32 	[%rd8], %f64;
	mul.f32 	%f65, %f46, %f65;
	st.f32 	[%SP+8], %f65;
BB48_14:                                // %_ZN7vector3IfE9normalizeEv.exit4
	mul.f32 	%f47, %f65, %f1;
	neg.f32 	%f48, %f47;
	fma.rn.f32 	%f67, %f15, %f63, %f48;
	setp.eq.f32	%p15, %f67, 0f00000000;
	mul.f32 	%f49, %f15, %f64;
	neg.f32 	%f50, %f49;
	fma.rn.f32 	%f68, %f4, %f65, %f50;
	setp.eq.f32	%p16, %f68, 0f00000000;
	and.pred  	%p17, %p16, %p15;
	mul.f32 	%f51, %f4, %f63;
	neg.f32 	%f52, %f51;
	fma.rn.f32 	%f66, %f64, %f1, %f52;
	setp.eq.f32	%p18, %f66, 0f00000000;
	and.pred  	%p19, %p17, %p18;
	@%p19 bra 	BB48_18;
	bra.uni 	BB48_15;
BB48_18:
	bra.uni 	BB48_16;
BB48_15:                                // %_ZNK7vector3IfE7is_nullEv.exit.thread.i
	mul.f32 	%f53, %f67, %f67;
	fma.rn.f32 	%f54, %f68, %f68, %f53;
	fma.rn.f32 	%f55, %f66, %f66, %f54;
	rsqrt.approx.ftz.f32 	%f56, %f55;
	mul.f32 	%f66, %f66, %f56;
	mul.f32 	%f67, %f67, %f56;
	mul.f32 	%f68, %f68, %f56;
BB48_16:                                // %_ZN7vector3IfE9normalizeEv.exit
	st.f32 	[%rd3], %f63;
	st.f32 	[%rd3+4], %f64;
	st.f32 	[%rd3+8], %f65;
	st.f32 	[%rd3+12], %f68;
	st.f32 	[%rd3+16], %f67;
	st.f32 	[%rd3+20], %f66;
	ret;
}

